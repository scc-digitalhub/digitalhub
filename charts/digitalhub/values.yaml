global:
  cleanup:
    persistentVolumeClaims: false
    ingress: false
    pods: false
    jobs: false
  service:
    type: &serviceType "NodePort"
  registry:
    url: 192.168.49.2:30150
    username: ""
    password: ""
    email: ""
    secretName: ""
  basicAuth:
    enabled: false
    username: ""
    password: ""
    secretName: ""
  nuclio:
    dashboard:
      nodePort: 30050
  externalHostAddress: &globalExternalUrl "192.168.49.2"
  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL

docker-registry:
  enabled: true
  fullnameOverride: digitalhub-docker-registry
  className: nginx
  service:
    type: *serviceType
    nodePort: 30150
  ingress:
    enabled: false
    path: /
    hosts:
      - registry.digitalhub.test
  persistence:
    accessMode: 'ReadWriteOnce'
    enabled: true
    size: 128Gi
  updateStrategy:
    type: Recreate

mlrun-ce:
  enabled: true
  nuclio:
    dashboard:
      kaniko:
        insecurePushRegistry: true
        insecurePullRegistry: true
  mlrun:
    ui:
      ingress:
        enabled: false
    db:
      enabled: true
    httpDB:
      dbType: "mysql"
      secretDsn:
        name: ""
        key: ""
    modelMonitoring:
      secretDsn:
        name: ""
  jupyterNotebook:
    enabled: false
  minio:
    enabled: true
    rootUser: minio
    rootPassword: minio123
    mode: standalone
    replicas: 1
    ingress:
      enabled: false
    persistence:
      enabled: true
      size: 128Gi
    buckets:
      - name: datalake
        policy: none
        purge: false
  pipelines:
    enabled: true
    name: pipelines
    persistence:
      enabled: true
      existingClaim:
      storageClass:
      accessMode: "ReadWriteOnce"
      size: "20Gi"
    db:
      username: root
    ui:
      ingress:
        enabled: false
    minio:
      enabled: true
      accessKey: "minio"
      secretKey: "minio123"
      endpoint: "minio"
      endpointPort: "9000"
      bucket: "datalake"
  kube-prometheus-stack:
    enabled: false

coder:
  enabled: true
  username: test
  password: Test12456@!
  email: test@digitalhub.test
  customCoderTemplates:
    - name: jupyter
      nodePort: "30040"
      iconUrl: https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Jupyter_logo.svg/1200px-Jupyter_logo.svg.png
    - name: dremio
      nodePort: "30120"
      iconUrl: https://cdn.icon-icons.com/icons2/2699/PNG/512/dremio_logo_icon_168234.png
    - name: sqlpad
      nodePort: "30140"
      iconUrl: https://i.ibb.co/TrBDsZM/sqlpad.png
    - name: grafana
      nodePort: "30130"
      iconUrl: https://cdn.icon-icons.com/icons2/2699/PNG/512/grafana_logo_icon_171048.png
    - name: dashboard
      nodePort: "30110"
      iconUrl: https://svgshare.com/i/u5R.svg
  coder:
    image:
      tag: v2.6.0
    env:
      - name: CODER_PG_USERNAME
        valueFrom:
          secretKeyRef:
            name: coder.coder-postgres-cluster.credentials.postgresql.acid.zalan.do
            key: username
      - name: CODER_PG_PASSWORD
        valueFrom:
          secretKeyRef:
            name: coder.coder-postgres-cluster.credentials.postgresql.acid.zalan.do
            key: password
      - name: CODER_PG_CONNECTION_URL
        value: "postgres://$(CODER_PG_USERNAME):$(CODER_PG_PASSWORD)@coder-postgres-cluster:5432/coder"
    ingress:
      enable: false
    service:
      type: *serviceType
      httpNodePort: "30170"

postgres-operator:
  enabled: true
  digitalhubDatabase:
    volume:
      size: 256Gi
    resources:
      requests:
        cpu: 1000m
        memory: 1000Mi
      limits:
        cpu: "4"
        memory: 8Gi

ext-postgres-operator:
  enabled: true
  postgres:
    host: database-postgres-cluster
    user: ""
    password: ""
    uri_args: " "
    cloud_provider: ""
    default_database: "postgres"
  postgresCredsExistingSecrets:
    username:
      secretName: "digitalhubadmin.database-postgres-cluster.credentials.postgresql.acid.zalan.do"
      secretKey: "username"
    password:
      secretName: "digitalhubadmin.database-postgres-cluster.credentials.postgresql.acid.zalan.do"
      secretKey: "password"

postgrest-operator:
  enabled: true
  postgres:
    host: database-postgres-cluster
    port: 5432
    uri_args: "sslmode=disable"
    default_database: "digitalhub"
    postgrest_service_type: NodePort
  postgresCredsExistingSecrets:
    username:
      secretName: "digitalhub-owner-user.database-postgres-cluster.credentials.postgresql.acid.zalan.do"
      secretKey: "username"
    password:
      secretName: "digitalhub-owner-user.database-postgres-cluster.credentials.postgresql.acid.zalan.do"
      secretKey: "password"

core:
  enabled: true
  minio:
    bucketName: datalake
    endpoint: "minio"
    endpointPort: "9000"
  service:
    type: *serviceType
    httpNodePort: "30180"
  postgres:
    host: database-postgres-cluster
    database: digitalhub
    port: "5432"
    schema: public
  config:
    rootUser: minio
    rootPassword: minio123
  krm:
    port: "8080"
  kfp:
    endpoint: "http://ml-pipeline:8888"

  events:
    enabled: false
    rabbitmq:
      enabled: false
      host: "digitalhub-rabbitmq"
      port: "5672"
      vhost: "/"
      queue: "dhCoreQueue"
      topic: "entityTopic"
      routingKey: "entityRoutingKey"
      credentials:
        existingSecret:
          name: "digitalhub-rabbitmq-default-user"
          usernameKey: "username"
          passwordKey: "password"

custom-resource-manager:
  enabled: true
  service:
    type: *serviceType
    httpNodePort: "30220"

dremio-rest-server-operator:
  enabled: true

apigw-operator:
  enabled: true

grafana:
  enabled: true
  rbac:
    namespaced: true
  adminPassword: digitalhub-test
  service:
    type: NodePort
    nodePort: 30210
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Postgres
          type: postgres
          url: database-postgres-cluster:5432
          user: ${username}
          secureJsonData:
            password: ${password}
          jsonData:
            database: digitalhub
            sslmode: 'require'
            maxOpenConns: 100
            maxIdleConns: 100
            maxIdleConnsAuto: true
            connMaxLifetime: 14400
            postgresVersion: 1500
            timescaledb: false
  plugins:
    - https://github.com/scc-digitalhub/grafana-dremio-datasource-plugin/raw/master/releases/digital-hub-dremio-1.1.1.zip;digital-hub-dremio
  envFromSecret: digitalhub-reader-user.database-postgres-cluster.credentials.postgresql.acid.zalan.do
  env:
    GF_PLUGINS_ALLOW_LOADING_UNSIGNED_PLUGINS: "digital-hub-dremio"

jobs:
  delete:
    securityContext:
      readOnlyRootFilesystem: true

rabbitmq-cluster-operator:
  enabled: false
  cluster:
    replicas: 1
    persistence:
      storagaClass: "standard"
      storageSize: "4Gi"

opensearch:
  enabled: false
  clusterName: opensearch
  fullnameOverride: opensearch
  nodeGroup: ""
  imagePullPolicy: Always
  opensearchJavaOpts: "-Xmx1g -Xms1g"
  persistence:
    size: 8Gi
  protocol: http
  config:
    opensearch.yml: |
      plugins.security.disabled: true
  singleNode: true
  resources:
    requests:
      cpu: "100m"
      memory: "256M"
    limits:
      cpu: "2000m"
      memory: "2048M"

airflow:
  enabled: false
  airflow:
    image:
      repository: docker.getcollate.io/openmetadata/ingestion
      tag: 1.2.5
      pullPolicy: "IfNotPresent"
    executor: "KubernetesExecutor"
    config:
      # This is required for OpenMetadata UI to fetch status of DAGs
      AIRFLOW__API__AUTH_BACKENDS: "airflow.api.auth.backend.session,airflow.api.auth.backend.basic_auth"
      # OpenMetadata Airflow Apis Plugin DAGs Configuration
      AIRFLOW__OPENMETADATA_AIRFLOW_APIS__DAG_GENERATED_CONFIGS: "/opt/airflow/dags"
      # OpenMetadata Airflow Secrets Manager Configuration
      AIRFLOW__OPENMETADATA_SECRETS_MANAGER__AWS_REGION: ""
      AIRFLOW__OPENMETADATA_SECRETS_MANAGER__AWS_ACCESS_KEY_ID: ""
      AIRFLOW__OPENMETADATA_SECRETS_MANAGER__AWS_ACCESS_KEY: ""
    users:
      - username: digitalhub
        role: Admin
        firstName: admin
        lastName: admin
        password: ${ADMIN_PASSWORD}
        email: admin@digitalhub.local
    usersTemplates:
      ADMIN_PASSWORD:
        kind: secret
        name: airflow-admin-password
        key: password
  web:
    extraVolumes:
    - name: pod-template
      configMap:
        name: openmetadata-pod-template
        defaultMode: 420
    extraVolumeMounts:
      - name: pod-template
        readOnly: true
        subPath: pod_template.yaml
        mountPath: /opt/airflow/pod_templates/pod_template.yaml
    readinessProbe:
      enabled: true
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 10
    livenessProbe:
      enabled: true
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 10
  postgresql:
    enabled: false
  workers:
    enabled: false
  flower:
    enabled: false
  redis:
    enabled: false
  externalDatabase:
    type: postgres
    host: airflow-postgres-cluster
    port: 5432
    database: airflow
    user: airflow
    passwordSecret: airflow.airflow-postgres-cluster.credentials.postgresql.acid.zalan.do
    passwordSecretKey: password
  serviceAccount:
    create: true
    name: "airflow"
  scheduler:
    logCleanup:
      enabled: false
  dags:
    persistence:
      enabled: true
      storageClass: "standard"
      size: 1Gi
      accessMode: ReadWriteMany
  logs:
    persistence:
      enabled: true
      storageClass: "standard"
      accessMode: ReadWriteMany
      size: 1Gi

openmetadata:
  enabled: false
  initializer:
    enabled: true
    maxRetry: "30"
    username: "admin"
    password: "admin"
  service:
    type: *serviceType
  nameOverride: openmetadata
  fullnameOverride: "openmetadata"
  openmetadata:
    config:
      database:
        enabled: true
        host: openmetadata-postgres-cluster
        port: 5432
        driverClass: org.postgresql.Driver
        databaseName: openmetadata
        dbScheme: postgresql
        dbParams: "&ssl=true&sslmode=require"
        auth:
          username: openmetadata
          password:
            secretRef: openmetadata.openmetadata-postgres-cluster.credentials.postgresql.acid.zalan.do
            secretKey: password
      pipelineServiceClientConfig:
        auth:
          enabled: true
          username: digitalhub
          password:
            secretRef: airflow-admin-password
            secretKey: password

openmetadata-java-connector:
  enabled: false
  connector:
    rabbitmq:
      host: "digitalhub-rabbitmq"
      port: "5672"
      virtualhost: "/"
      existingSecrets:
        username:
          secretName: "digitalhub-rabbitmq-default-user"
          secretKey: "username"
        password:
          secretName: "digitalhub-rabbitmq-default-user"
          secretKey: "password"
    openmetadata:
      host: "http://openmetadata:8585/api"
      dataserviceName: "DigitalHub"
      dataserviceSql: "DigitalHubSQL"
      dataserviceS3: "DigitalHubS3"
      existingSecrets:
        token:
          secretName: "openmetadata-bot-token"
          secretKey: "token"

nakamasato-mysql-operator:
  enabled: false

mysql-operator:
  enabled: false

template-controller:
  enabled: true

oauth2-proxy:
  enabled: false
  apps:
    - name: ""
      service:
        name: ""
        port: ""
      ingress:
        enabled: false
        annotations: {}
        ingressClassName: ""
        hosts: []
        path: /
        tls: []
      redirectUrl: ""
      oidcIssuerUrl: ""
      existingSecret:
        name: ""
        clientId: ""
        secretKey: ""
